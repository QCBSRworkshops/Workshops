---
title: "Workshop 7: Generalized linear (mixed) models"
subtitle: "QCBS R Workshop Series"
author: "Québec Centre for Biodiversity Science"
output:
  xaringan::moon_reader:
    includes:
      in_header: qcbsR-header.html
    lib_dir: assets
    seal: true
    css: ["default", "qcbsR.css", "qcbsR-fonts.css"]
    nature:
      beforeInit: "qcbsR-macros.js"
      highlightLines: true
---


```{r setup, echo = F}
knitr::opts_chunk$set(
  comment = "#",
  collapse = TRUE,
  cache = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width=6, fig.height=6,
  fig.align = 'center'
)
mypar = list(mar = c(3,3,1,0.5), mgp = c(1.6, 0.3, 0), tck = -.02)

# add packages
if (!suppressPackageStartupMessages(require(ggplot2))) {
  install.packages("ggplot2")
}
if (!suppressPackageStartupMessages(require(MASS))) {
  install.packages("MASS")
}
if (!suppressPackageStartupMessages(require(binomTools))) {
  # file name
  f = file.path(tempdir(), "biomTools")
  # download package file
  download.file('https://cran.r-project.org/src/contrib/Archive/binomTools/binomTools_1.0-1.tar.gz', destfile = f, method = 'curl')
  # install from source
  system(paste('R CMD INSTALL', f))
}
if (!suppressPackageStartupMessages(require(coefplot2))) {
  install.packages("coefplot2", repos = "http://www.math.mcmaster.ca/bolker/R", type="source")
}
if (!suppressPackageStartupMessages(require(gridExtra))) {
  install.packages("gridExtra")
}
if (!suppressPackageStartupMessages(require(lme4))) {
  install.packages("lme4")
}
if (!suppressPackageStartupMessages(require(lattice))) {
  install.packages("lattice")
}
if (!suppressPackageStartupMessages(require(bbmle))) {
  install.packages("bbmle")
}
```


## Outline

1. Why be normal? .small[(*Your data is ok; it's the model that's wrong*)]
2. GLM with binary data
3. GLM with count data
4. GLMMs

---
class: inverse, center, middle

# Why be normal?

## Your data is ok;
## it's the model that's wrong

---
## Limitations of linear (mixed) models

Load dataset and fit a linear model (`lm()`):

```{r,echo=FALSE}
  mites <- read.csv('data/mites.csv')
```

```{r,eval=F}
  # make sure you're in the right working directory
  mites <- read.csv('mites.csv')
  head(mites)
  str(mites)
```

The dataset that you just loaded is a subset of the 'Oribatid mite dataset'

.small[
> 70 moss and mite samples

> 5 environmental measurements and abundance of the mite *Galumna sp.*
]

**Goal**: Model the abundance (`abund`), occurrence (`pa`), and proportion (`prop`) of Galumna as a function of the 5 environmental variables.

---
## Exploring relationships

Can we see any relationship(s) between Galumna and the 5 environmental variables?

---
## Exploring relationships

.small[Can we see any relationship(s) between Galumna and the 5 environmental variables?]

.pull-left2[
```{r,echo = -1}
  par(mypar)
  plot(mites)
```
]
.pull-right2[
<br><br><br><br><br>
`Galumna` vs `WatrCont`?!
]

---
## Exploring relationships

A negative relationship between `Galumna` and water `content`?

```{r,fig.width=12,fig.height=4.5,echo=-1}
  par(mypar)
  par(mfrow = c(1, 3), cex = 1.4)
  plot(Galumna ~ WatrCont, data = mites, xlab = 'Water content', ylab='Abundance')
  boxplot(WatrCont ~ pa, data = mites, xlab='Presence/Absence', ylab = 'Water content')
  plot(prop ~ WatrCont, data = mites, xlab = 'Water content', ylab='Proportion')
```

---
## Testing linearity

Fit linear models to test whether `abund`, `pa`, and/or `prop` varies as a function of water content.

--
```{r, eval = -c(2, 4, 6)}
  lm.abund <- lm(Galumna ~ WatrCont, data = mites)
  summary(lm.abund)
  lm.pa <- lm(pa ~ WatrCont, data = mites)
  summary(lm.pa)
  lm.prop <- lm(prop ~ WatrCont, data = mites)
  summary(lm.prop)
```

--
.pull-left[
```{r}
summary(lm.abund)$coefficients[, 4]
summary(lm.abund)$coefficients[, 4]
summary(lm.abund)$coefficients[, 4]
```
]
.pull-right[
Significant relationship in all models!

.alert[But...]
]

---
## Testing linearity

Significant relationship in all models! .alert[Wait a minute...]

.pull-left[
```{r,echo=-1}
par(mypar);par(cex = 1.4)
plot(Galumna ~ WatrCont, data = mites)
abline(lm.abund)
```
]

.pull-right[
```{r,echo=-1}
par(mypar)
par(mfrow = c(2, 2), cex = 1.4)
plot(lm.abund)
```
]

---
## Testing linearity

Even worse for other models (Proportion `prop`):

.pull-left[
```{r,echo=-1}
par(mypar);par(cex = 1.4)
plot(prop ~ WatrCont, data = mites)
abline(lm.prop)
```
]

.pull-right[
```{r,echo=-1}
par(mypar)
par(mfrow = c(2, 2), cex = 1.4)
plot(lm.prop)
```
]

---
## Testing linearity

Even worse for other models (Presence/Absence `pa`):

.pull-left[
```{r,echo=-1}
par(mypar);par(cex = 1.4)
plot(pa ~ WatrCont, data = mites)
abline(lm.pa)
```
]

.pull-right[
```{r,echo=-1}
par(mypar)
par(mfrow = c(2, 2), cex = 1.4)
plot(lm.pa)
```
]

---
## Model assumptions

Common in Ecology that assumptions of homogeneity of variance and normality are not met.
  - Main reason why we need GLMs!

.comment[Let's revisit the assumptions of lm...]

---
## Model assumptions

Equation of lm:

$y = \beta_0 + \beta_1x_i + \varepsilon$

where:

$y_i$ = predicted value of response variable

$\beta_0$ = intercept

$\beta_1$ = slope

$x_i$ = explanatory variable

$\varepsilon_i$ = model residuals drawn from a normal distribution with a varying mean but a constant variance**

.comment[.alert[**Key point!] Residuals (the distance between each observation and the regression line) can be predicted by drawing random values from a normal distribution.]

---
## Normally distributed residuals

Recall: Normal distributions have two parameters, $\mu$ (mean) and $\sigma$ (variance):

<br>
.pull-left[
Varing $\mu$, $\sigma = 5$

```{r,echo=F}
x = seq(1, 50, 0.1)
par(mypar);par(cex = 1.4)
plot(x, dnorm(x, mean = 20, sd = 5), type = 'l', lwd = 3, xlab = '# galumna', ylab = 'Probability')
points(x, dnorm(x, mean = 25, sd = 5), type = 'l', lwd = 3, col = 2)
points(x, dnorm(x, mean = 30, sd = 5), type = 'l', lwd = 3, col = 4)
legend('topleft', legend = c('20', '25', '30'), lty = 1, col = 1:3, bty = 'n', lwd = 2, cex = 1.1)
```
]
.pull-right[
$\mu = 25$, varing $\sigma$

```{r,echo=F}
x = seq(1, 50, 0.1)
par(mypar);par(cex = 1.4)
plot(x, dnorm(x, mean = 25, sd = 5), type = 'l', lwd = 3, xlab = '# galumna', ylab = 'Probability')
points(x, dnorm(x, mean = 25, sd = 7.5), type = 'l', lwd = 3, col = 2)
points(x, dnorm(x, mean = 25, sd = 10), type = 'l', lwd = 3, col = 4)
legend('topleft', legend = c('5', '7.5', '10'), lty = 1, col = 1:3, bty = 'n', lwd = 2, cex = 1.1)
```
]

---
## Normally distributed residuals

Another way to write the lm equation is:

$y_i \sim N(\mu = \beta_0 + \beta_1 X_i, \sigma^2)$

<br>
Which literally means that $y_i$ is drawn from a normal distribution with parameters $\mu$ (which depends on $x_i$) and $\sigma$ (which has the same value for all $Y$s)

<br>
.comment[Lets predict Galumna abund as a function of water content using the `lm` we fitted earlier...]

---
## Model prediction

We need regression coefficients ( $\beta$) and $\sigma$:

```{r}
coef(lm.abund)
summary(lm.abund)$sigma
```

What are the parameters of the normal distribution used to model $y$ when water content = 300?

$y_i \sim N(\mu = \beta_0 + \beta_1 X_i, \sigma^2)$

--

$\mu = 3.44 + (-0.006 x 300) = 1.63$

$\sigma = 1.51$

---
## Model prediction

- At $x = 300$, residuals should follow a normal distribution with $\mu = 1.63$ and $\sigma^2 = 1.51$.

- At $x = 400$, we get $\mu = 1.02$ and $\sigma^2 = 1.51$, etc.

<br>
Graphically, this is our model:

--
.pull-left[
.center[
  ![:scale 100%](images/modelPredic.png)
]]
--
.pull-right[
**Problems**:
- $\sigma^2$ is not homogeneous, yet `lm()` forces a constant $\sigma^2$
- Predicted values should be integers
]

---
## Biological data & distributions

Statisticians have described a multitude of distributions that correspond to different types of data

A distribution provides the probability of observing each possible outcome of an experiment or survey (e.g. $abund = 8$ Galumna)

Distributions can be **discrete** (only includes integers
or **continuous** (includes fractions)

All distributions have **parameters** that dictate the shape of the distribution (e.g. $\mu$ and $\sigma^2$ for the normal)

---
## Biological data & distributions

Galumna abund follows a discrete distribution (can only take integer values).

A useful distribution to model abundance data is the “Poisson” distribution:

  - a discrete distribution with a single parameter, $\lambda$ (lambda), which defines both the mean and the variance of the distribution:

```{r,echo=F,fig.width=15}
x = seq(1, 50, 1)
par(mypar);par(mfrow = c(1, 3), cex = 1.4)
plot(x, dpois(x, lambda = 1), type = 'h', lwd = 3, xlab = '# galumna', ylab = 'Probability', main = 'lambda = 1')
plot(x, dpois(x, lambda = 10), type = 'h', lwd = 3, xlab = '# galumna', ylab = 'Probability', main = 'lambda = 10')
plot(x, dpois(x, lambda = 30), type = 'h', lwd = 3, xlab = '# galumna', ylab = 'Probability', main = 'lambda = 30')
```

---
## Biological data & distributions

Galumna seems to follow a Poisson distribution with a low value of $\lambda$:

.pull-left[
```{r}
  hist(mites$Galumna)
```
]
.pull-right[
```{r}
  mean(mites$Galumna)
```
]

---
## Biological data & distributions

Presence-absence takes yet another form:

- only `0`s and `1`s
- Poisson distribution would not be appropriate to model this variable

```{r,fig.height=5,echo=-1}
  par(mypar);par(cex=1.4)
  hist(mites$pa)
```

---
## Biological data & distributions

**“Bernoulli” distribution**:

- Only two possible outcomes in its range: success (`1`) or failure (`0`)
- One parameter, $p$, the probability of success

<br>
```{r,echo=-F,fig.width=12,fig.height=4}
  par(mypar);par(mfrow = c(1, 3), cex=1.4)
  barplot(setNames(c(.9, .1), c('absent (0)', 'present (1)')), ylim = c(0, 1), xlab = 'pa', ylab = 'probability', main = 'p = 0.1')
  barplot(setNames(c(.5, .5), c('absent (0)', 'present (1)')), ylim = c(0, 1), xlab = 'pa', ylab = 'probability', main = 'p = 0.5')
  barplot(setNames(c(.1, .9), c('absent (0)', 'present (1)')), ylim = c(0, 1), xlab = 'pa', ylab = 'probability', main = 'p = 0.9')
```

We can use the Bernouilli distribution to calculate the probability Galumna present (`1`) vs. absent (`0`)

---
## Biological data & distributions

**Binomial distribution**: When there are multiple trials (each with a success/failure), the Bernoulli distribution expands into the binomial
- Additional parameter, n, for number of trials
- Predicts the probability of observing a given proportion of successes, p, out of a known total number of trials, $n$

```{r,echo=F,fig.width=15}
x = seq(1, 50, 1)
par(mypar);par(mfrow = c(1, 3), cex = 1.4)
plot(x, dbinom(x, size = 50, prob = 0.1), type = 'h', lwd = 3, xlab = '# galumna', ylab = 'Probability', main = 'p = 0.1 n = 50')
plot(x, dbinom(x, size = 50, prob = 0.5), type = 'h', lwd = 3, xlab = '# galumna', ylab = 'Probability', main = 'p = 0.5 n = 50')
plot(x, dbinom(x, size = 50, prob = 0.9), type = 'h', lwd = 3, xlab = '# galumna', ylab = 'Probability', main = 'p = 0.9 n = 50')
```

---
## Biological data & distributions

**Binomial distribution**: used to model data where the number of successes are integers and where the number of trials, n, is known.

**Main difference with Poisson distribution**: the binomial has an upper limit to its range, corresponding to `n`. Consequently, it is right-skewed at low p values but left-skewed at high `p` values

```{r,echo=F,fig.width=10, fig.height=5}
x = seq(1, 50, 1)
par(mypar);par(mfrow = c(1, 2), cex = 1.4)
plot(x, dbinom(x, size = 50, prob = 0.9), type = 'h', lwd = 3, xlab = '# galumna', ylab = 'Probability', main = 'p = 0.9 n = 50')
plot(x, dpois(x, lambda = 30), type = 'h', lwd = 3, xlab = '# galumna', ylab = 'Probability', main = 'lambda = 30')
```

---
## Biological data & distributions

Getting back to our problem... can switch the distribution of error terms (εi) from normal to Poisson:

$$y_i \sim Poisson(\lambda = \beta_0 + \beta_1 x_i)$$

Problems solved!

1. $\lambda$ varies with $x$ (water content) which means residual variance will also vary with $x$, which means that we just relaxed the homogeneity of variance assumption!

2. Predicted values will now be integers instead of fractions

3. The model will never predict negative values (Poisson is strictly positive)

---
## Biological data & distributions

This is **almost** a Poisson GLM, which looks like this:

.center[![:scale 90%](images/poisPred.png)]

Probabilities (in orange) are now integers, and both the variance and the mean of the distribution decline as $\lambda$ decreases with increasing water content.


---
class: inverse, center, middle

# GLM with binary data

---
## Binary variables

Common response variable in ecological datasets is the binary variable: we observe a phenomenon X or its “absence”

- Presence/Absence of a species
- Presence/Absence of a disease
- Success/Failure to observe behaviour
- Survival/Death of organisms

Wish to determine if $P/A \sim Environment$ .comment[*]

.comment[Called a logistic regression or logit model]

---
## Binary variables

In `R`, binary variables are coded with `1` and `0`:

```{r,echo=F}
Site <- LETTERS[1:6]
Presence <- c(1, 0, 1, 1, 0, 1)
dat = data.frame(Site, Presence)
```

<br>

.pull-left[
.right[
```{r, echo=F}
print(dat)
```
]]
.pull-right[
 <br>

 1 = Presence

 <br>

 0 = Absence
]

---
## Binary variables

Clearly not normally distributed!

<br>

```{r,echo=F,fig.width=7, fig.height=6}
par(mypar);par(cex = 1.4)
hist(Presence)
```

---
## Binary variables

Expected values can be out of the `[0,1]` range with `lm()`:

<br>

```{r,echo=F,fig.width=7.5, fig.height=5.6}
Pres <- c(rep(1, 40), rep(0, 40))
rnor <- function(x) rnorm(1, mean = ifelse(x == 1, 12.5, 7.5), sd = 2)
ExpVar <- sapply(Pres, rnor)
par(mypar);par(cex = 1.4)
plot(ExpVar, Pres, ylim = c(-.5, 1.5), xlab = 'Explanatory variable', ylab = 'Presence', main = 'Binary variables and fitted values with lm()', pch = 16)
abline(lm(Pres ~ ExpVar), col = 'orange', lwd = 2)
mtext(expression(symbol("\255")), at = 1.25, side = 4, line = 0.1, cex = 6, col = 'blue')
mtext(expression(symbol("\256")), at = 3, side = 1, line = -2.2, cex = 6, col = 'blue')
```

---
## Probability distribution

The Bernoulli distribution is well suited for binary response variables

<br>

.pull-left[.right[

$E(Y) = p$

<br>

$Var(Y) = p \times (1 - p)$

]]
.pull-right[

![:faic](arrow-right) **Mean of distribution** .small[Probability $p$ of observing an outcome]

![:faic](arrow-right) **Variance of distribution** .small[Variance decreases as $p$ is close to `0` or `1`]
]

---
## Logistic regression

The `glm()` function!

<br>

`logit.reg <- glm(formula, data, family)`

<br>

To move away from traditional linear models, need to specify two things (`family`):

1. probability distribution

**AND**

2. a link function

---
## The Link Function

For a simple linear model of a normally distributed continuous response variable, the equation for the expected values is:

<br>

$$\mu = x\beta$$

where

- $\mu$ is the expected value of the response variable
- $x$ is the model matrix (*i.e.* your data)
- $\beta$ is the vector of estimated parameters (*i.e.* the intercept & slope)

<br>

$x\beta$ is called the **linear predictor**

---
## The Link Function

$\mu = x\beta$ is only true for normally distributed data

If this is not the case, must use a transformation on the expected values $\mu$

$$g(\mu) = x\beta$$

where $g(\mu)$ is the link function

<br>

This allows us to relax the normality assumption

---
## The Link Function

For binary data, the link function is called the **logit**:

<br>

$$g(\mu) = log\frac{\mu}{1-\mu}$$

$\mu =$ expected values (probability that $Y = 1$)

<br>

- Get the odds ( $\frac{\mu}{1-\mu}$)
- log-transform them

---
## The Link Function

$$g(\mu) = log\frac{\mu}{1-\mu}$$

- Get the odds ( $\frac{\mu}{1-\mu}$)
- log-transform them

<br>
The odds puts our expected values on a `0` to `+Inf` scale

The log transformation puts our expected values on a `-Inf` to `+Inf`

![:faic](arrow-right) The expected values can now be **linearly** related to the linear predictor

---
## Exercise 1

Build a logistic regression model using the mites data

```{r,eval=F}
#setwd('...')
mites <- read.csv("mites.csv", header = TRUE)
str(mites)

```{r,echo=F}
mites <- read.csv("data/mites.csv", header = TRUE)
str(mites)
```

---
## Exercise 1

Build a model of the presence of Galumna sp. as a function of water content and topography

```{r}
logit.reg <- glm(pa ~ WatrCont + Topo, data=mites,
family = binomial(link = "logit"))
```
```{r,eval=F}
summary(logit.reg)
```

---
## Exercise 1

.small[
```{r}
summary(logit.reg)
```
]

---
## Challenge 1 ![:cube]()

Using the 'bacteria' dataset, model the presence of *H. influenzae* as a function of treatment and week of test.

Start with a full model and reduce it to the most parsimonious model.

```{r}
#install.packages("MASS")
library(MASS)
data(bacteria)
str(bacteria)
```

---
## Solution ![:cube]()

```{r}
model.bact1 <- glm(y ~ trt * week, data = bacteria, family = binomial)
```

```{r}
model.bact2 <- glm(y ~ trt + week, data = bacteria, family = binomial)
```

```{r}
model.bact3 <- glm(y ~ week, data = bacteria, family = binomial)
```

```{r}
anova(model.bact1, model.bact2, model.bact3, test = "LRT")
```

---
## Interpreting the output

Let's go back to the summary of our `logit.reg` model to see the coefficients:

```{r}
summary(logit.reg)$coefficients
```

The output indicates that both water content and topography are significant

.comment[But how do we interpret the slope coefficients?]

---
## Interpreting the output

Remember we used a logit transformation on the expected values!

To properly interpret the regression parameters, we have to use a 'reverse' function:

<br>
The natural exponential function to obtain the odds: $e^x$

The inverse logit function to obtain the probabilities:

$$logit^{-1} = \frac{1}{1 + \frac{1}{e^x}}$$

---
## Interpreting the output

On the odds scale for water content:

```{r}
exp(logit.reg$coefficient[2])
```

On the probability scale for water content:

```{r}
1 / (1 + 1/exp(logit.reg$coefficient[2]))
```

---
## Predictive Power and goodness of fit

Get the pseudo-R², the analogue of the $R^2$ for models fitted by maximum likelihood:

$$\text{pseudo-R}^2 = \frac{\text{null deviance - residual deviance}}{\text{null deviance}}$$

<br>

$\text{pseudo-R}^2 = \text{variance explained by the model}$

---
## Predictive Power and goodness of fit

Comparing deviance of your model (residual deviance) to the deviance of a null model (null deviance)

The **null model** is a model without explanatory variables

```R
null.model <- glm(Response.variable ~ 1, family = binomial)
```

---
## Predictive Power and goodness of fit

In R, we can extract the residual and null deviances directly from the glm object:

```{r}
objects(logit.reg)
```

```{r}
pseudoR2 <- (logit.reg$null.deviance - logit.reg$deviance) / logit.reg$null.deviance
pseudoR2
```

.comment[Hence, the model explains 46.6% of the variability in the data]

---
## Predictive Power and goodness of fit

New statistic - **coefficient of discrimination (D)** evaluates the predictive power of logistic regression

- Measure of how well logistic regression classifies an outcome as a success or a failure

To assess goodness of fit, diagnostic plots are not useful, instead must use **Hosmer-Lemeshow test**:

- Compare observed and expected number of outcomes
- Similar to a Chi square test

---
## Exercise 2

In R these tests are available in the `binomTools` package

Compute the coefficient of discrimination D

```{r}
fit <- binomTools::Rsq(object = logit.reg)
fit
```

---
#### Exercise 2: Perform a Hosmer-Lemeshow test .comment[*]

.small[
```{r}
binomTools::HLtest(binomTools::Rsq(model.bact2))
```
]

.comment[A non significant value indicates an adequate fit!]

---
## Challenge 1 ![:cube]()

1. Using the model created with bacteria dataset, assess goodness of fit and predictive power.

2. Think how predictive power could be improved for this model.

---
## Solution ![:cube]()

1:
```{r,eval=F}
null.d <- model.bact2$null.deviance
resid.d <- model.bact2$deviance
bact.pseudoR2 <- (null.d -resid.d) / null.d
HLtest(Rsq(model.bact2)
```

2: Adding informative explanatory variables could increase the explanatory power of the model

---
## Proportion data and GLM

Sometimes, proportion data is more similar to logistic regression than you think...

If we measure the number of occurrences and we know the total sample size, it is not count data!

Suppose we measure disease prevalence in ten deer populations on 10 deer individuals per population:


.pull-left[

$$\frac{x\,\, \text{infected deer}}{10\,\,\text{deer}}$$

]

.pull-right[
![:faic](arrow-right) always bound between `0` and `1`!
]

---
## Exercise 3

In R, we have to specify the number of times something happened and the number of times something did not happen:

```{r}
prop.reg <- glm(cbind(Galumna, totalabund - Galumna) ~ Topo + WatrCont, data = mites, family = binomial)
```

```r
summary(prop.reg)
```

---
## Exercise 3

.small[
```{r}
summary(prop.reg)
```
]

---
## Exercise 3

We can also code the model directly with proportions :

```{r}
prop.reg2 <- glm(prop ~ Topo + WatrCont, data = mites,
                 family = binomial, weights = totalabund)
```


---
class: inverse, center, bottom

# Thank you for attending this workshop!

![:scale 50%](images/QCBS_logo.png)
